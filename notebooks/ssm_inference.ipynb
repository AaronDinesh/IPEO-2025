{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SSM test-set exploration and inference\n",
        "\n",
        "Update `SSM_CHECKPOINT_PATH` to point to your saved State Space Model checkpoint, then run the notebook to visualize a sample and see predicted species scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision.models import ResNet18_Weights, ResNet50_Weights\n",
        "\n",
        "from src.models.ssm.ssm import StateSpaceModel\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "TEST_SET_PATH = \"../data/validation_set.npz\"\n",
        "SSM_CHECKPOINT_PATH = \"../checkpoints/ssm_checkpoint.pt\"  # <-- update this\n",
        "BACKBONE = \"resnet50\"  # set to the backbone used during training (\"resnet18\" or \"resnet50\")\n",
        "SAMPLE_INDEX = 0\n",
        "TOP_K = 5\n",
        "PREDICTION_THRESHOLD = 0.5\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "npz = np.load(TEST_SET_PATH)\n",
        "env = npz[\"env\"]\n",
        "landsat = npz[\"landsat\"]\n",
        "images = npz[\"images\"]\n",
        "labels = npz[\"labels\"]\n",
        "\n",
        "sample_idx = int(np.clip(SAMPLE_INDEX, 0, env.shape[0] - 1))\n",
        "\n",
        "# try:\n",
        "#     import pandas as pd\n",
        "\n",
        "#     env_cols = (\n",
        "#         pd.read_csv(ROOT / \"data\" / \"env_variables_test.csv\")\n",
        "#         .drop(columns=[\"surveyId\", \"Bio3\", \"Bio5\", \"Bio6\"])\n",
        "#         .columns.tolist()\n",
        "#     )\n",
        "# except Exception:\n",
        "#     env_cols = [f\"env_{i}\" for i in range(env.shape[1])]\n",
        "\n",
        "# ts_channels = [f\"c{i}\" for i in range(landsat.shape[2])]\n",
        "\n",
        "# print(f\"Loaded test set from {TEST_SET_PATH}\")\n",
        "# print(f\"env: {env.shape}, landsat: {landsat.shape}, images: {images.shape}, labels: {labels.shape}\")\n",
        "# print(f\"Sample index in use: {sample_idx}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_env = env[sample_idx]\n",
        "sample_ts = landsat[sample_idx]\n",
        "sample_img = images[sample_idx]\n",
        "sample_labels = labels[sample_idx]\n",
        "\n",
        "img_hwc = np.transpose(sample_img, (1, 2, 0))\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
        "\n",
        "axes[0].imshow(img_hwc)\n",
        "axes[0].axis(\"off\")\n",
        "axes[0].set_title(\"RGB patch\")\n",
        "\n",
        "for i in range(sample_ts.shape[1]):\n",
        "    axes[1].plot(sample_ts[:, i], label=ts_channels[i])\n",
        "axes[1].set_title(\"Landsat time series\")\n",
        "axes[1].set_xlabel(\"time step\")\n",
        "axes[1].legend(ncol=3, fontsize=8)\n",
        "\n",
        "axes[2].bar(range(sample_env.shape[0]), sample_env)\n",
        "axes[2].set_xticks(range(len(env_cols)))\n",
        "axes[2].set_xticklabels(env_cols, rotation=90)\n",
        "axes[2].set_title(\"Environmental features\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "positive_indices = np.nonzero(sample_labels)[0].tolist()\n",
        "preview = positive_indices[:20]\n",
        "more = \"...\" if len(positive_indices) > len(preview) else \"\"\n",
        "print(f\"Positive species indices ({len(positive_indices)} total): {preview}{more}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_image_transform(backbone: str):\n",
        "    if backbone == \"resnet18\":\n",
        "        weights = ResNet18_Weights.DEFAULT\n",
        "    else:\n",
        "        weights = ResNet50_Weights.DEFAULT\n",
        "    return weights.transforms(), weights\n",
        "\n",
        "\n",
        "def preprocess_image(img_array: np.ndarray, transform):\n",
        "    img_hwc = np.transpose(img_array, (1, 2, 0))\n",
        "    img_pil = Image.fromarray(img_hwc)\n",
        "    if img_pil.mode != \"RGB\":\n",
        "        img_pil = img_pil.convert(\"RGB\")\n",
        "    return transform(img_pil)\n",
        "\n",
        "\n",
        "def load_ssm_model(checkpoint_path: Path, env_dim: int, ts_channels: int, num_species: int, device, backbone: str):\n",
        "    raw_ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "    state_dict = raw_ckpt.get(\"model_state\", raw_ckpt)\n",
        "\n",
        "    state_dim = state_dict[\"state_init\"].shape[1]\n",
        "    model = StateSpaceModel(\n",
        "        num_species=num_species,\n",
        "        state_dim=state_dim,\n",
        "        env_dim=env_dim,\n",
        "        time_series_channels=ts_channels,\n",
        "        img_freeze_backbone=True,\n",
        "        img_backbone=backbone,\n",
        "    )\n",
        "    load_status = model.load_state_dict(state_dict, strict=False)\n",
        "    if load_status.missing_keys or load_status.unexpected_keys:\n",
        "        print(\"load_state_dict warnings:\")\n",
        "        if load_status.missing_keys:\n",
        "            print(\"  missing:\", load_status.missing_keys)\n",
        "        if load_status.unexpected_keys:\n",
        "            print(\"  unexpected:\", load_status.unexpected_keys)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    img_transform, _ = build_image_transform(backbone)\n",
        "    return model, img_transform, backbone\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not SSM_CHECKPOINT_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Checkpoint not found at {SSM_CHECKPOINT_PATH}. Update SSM_CHECKPOINT_PATH and rerun.\"\n",
        "    )\n",
        "\n",
        "model, img_transform, backbone = load_ssm_model(\n",
        "    checkpoint_path=SSM_CHECKPOINT_PATH,\n",
        "    env_dim=env.shape[1],\n",
        "    ts_channels=landsat.shape[2],\n",
        "    num_species=labels.shape[1],\n",
        "    device=DEVICE,\n",
        "    backbone=BACKBONE,\n",
        ")\n",
        "print(f\"Loaded backbone: {backbone}\")\n",
        "\n",
        "env_tensor = torch.tensor(env[sample_idx], dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
        "ts_tensor = torch.tensor(landsat[sample_idx], dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
        "img_tensor = preprocess_image(images[sample_idx], img_transform).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(env=env_tensor, ts=ts_tensor, img=img_tensor)\n",
        "    logits = outputs.logits[-1]\n",
        "    probs = torch.sigmoid(logits).squeeze(0).cpu()\n",
        "\n",
        "k = min(TOP_K, probs.numel())\n",
        "top_vals, top_idx = torch.topk(probs, k=k)\n",
        "print(f\"Top-{k} species indices:\")\n",
        "for score, idx in zip(top_vals.tolist(), top_idx.tolist()):\n",
        "    print(f\"  {idx}: {score:.4f}\")\n",
        "\n",
        "positive_pred = (probs >= PREDICTION_THRESHOLD).nonzero(as_tuple=False).flatten().tolist()\n",
        "preview_pred = positive_pred[:20]\n",
        "more_pred = \"...\" if len(positive_pred) > len(preview_pred) else \"\"\n",
        "print(\n",
        "    f\"Predicted positive species @ {PREDICTION_THRESHOLD:.2f} ({len(positive_pred)} total): {preview_pred}{more_pred}\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
